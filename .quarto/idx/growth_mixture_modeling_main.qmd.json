{"title":"Growth Mixture Modeling","markdown":{"headingText":"Growth Mixture Modeling","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"\n#### Growth mixture models (GMM)\n\nExample 2. Growth Mixture Modeling (GMM) On some occasions the conventional LGM may be limited in that it describes all individuals as coming from the same population, not accounting for potentially important subgroup effects. An important extension of the conventional model, GMM allows different unobserved subgroups to follow distinct trajectories. By allowing the intercept and slope growth factors to vary across groups, the GMM approach estimates a distinct group-mean trajectory with its own unique variance, for each latent class. A special case of GMM, LCGA models a separate trajectory for each latent class, but the growth factor variances [Clearer to say intercept and slope variances rather than growth factor?] within each class are fixed to zero (i.e., assumes homogenous within-class patterns of growth). As this approach is less computationally expensive, it is often a useful starting approach for identifying different underlying trajectories prior conducting a GMM. Expanding on our prior example, we now examine a GMM using the same BPM Externalizing scale scores used in the conventional model. A successive number of latent classes were specified across models and the optimal number of classes were determined by investigating recommended model selection criteria (e.g., adjusted Bayesian Information Criterion [aBIC], Bootstrapped Likelihood Ratio Test [BLRT], parsimony, and interpretability). An overview of criteria used to select the optimal number of trajectory classes is provided in Table 3. These results show aBIC to decrease across iterations, however, BLRT suggests a 4-class solution offers the optimal fit. Further, examination of the 5-class model reveals two classes that comprise less than 5% of the sample (class 3 n = 11 [\\< 1%]; class 4 n = 63 [3%]). Therefore, based on substantive interpretation, parsimony, and fit, we opt to select the four-class model of BPM Externalizing scores as providing the best overall solution. Estimated model parameters are presented in Table 4. Kenny's comment regarding previous sentence: This is one of those areas where some might argue there are too many investigator degrees of freedom. I also wonder whether there should be discussion of other issues like factor mixture models. nonlinear \n\nresults show a small (n = 64; 4%) group of youth with a persistently high BPM Externalizing trajectory and large group of youth (n = 1437; 77%) following a low and decreasing trajectory. The remaining two classes were characterized by youth with moderate initial scores that decreased across assessments (n = 191; 10%) and youth with moderate scores that remained stable over time (n = 171; 9%) (see Figure 2). Kenny's comment: I don't see \"figure 2\" here. Also, I might label groups as \"Moderate-High decreasing and Moderate -Low Stable. I say there because the intercept mean between the two\"moderates\" is larget than between Moderate Decreasing and Persistent High and between Moderate Stable and Low decreasing."},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"growth_mixture_modeling_main.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.258","comments":{"hypothesis":true},"bibliography":["references.bib"],"theme":"cosmo","code-copy":true},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","include-in-header":{"text":"\\usepackage{makeidx}\n\\makeindex\n"},"include-after-body":{"text":"\\printindex\n"},"output-file":"growth_mixture_modeling_main.pdf"},"language":{},"metadata":{"block-headings":true,"comments":{"hypothesis":true},"bibliography":["references.bib"],"documentclass":"scrreprt"},"extensions":{"book":{}}}}}