[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Welcome\nThis is the current landing page for the Biostats Working Group Longitudinal Analysis Project"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  IntroductionDIFFSCORE",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Difference Scores_Basic Example.html",
    "href": "Difference Scores_Basic Example.html",
    "title": "2  Difference Scores_Basic Example",
    "section": "",
    "text": "# Install necessary packages (if not already installed)\nif (!(\"lme4\" %in% installed.packages())) install.packages(\"lme4\")\nif (!(\"lmerTest\" %in% installed.packages())) install.packages(\"lmerTest\")\nif (!(\"tidyverse\" %in% installed.packages())) install.packages(\"tidyverse\")\nif (!(\"ggpubr\" %in% installed.packages())) install.packages(\"ggpubr\")\n\n\n#Load packages\nlibrary(lme4)\n\nLoading required package: Matrix\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\n\nlibrary(ggpubr)\n\n\ndf_wide<- read_csv(\"./df_wide.csv\")\n\nRows: 5649 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): ids\ndbl (26): SiteID, FamilyID, Sex, Age, Race_White, Race_Black, Race_Hispanic,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(df_wide)\n\nspc_tbl_ [5,649 × 27] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ids                   : chr [1:5649] \"NDAR_INV003RTV85\" \"NDAR_INV00CY2MDM\" \"NDAR_INV00HEV6HB\" \"NDAR_INV00LH735Y\" ...\n $ SiteID                : num [1:5649] 7 21 13 4 12 5 18 7 20 17 ...\n $ FamilyID              : num [1:5649] 7232 4495 1918 4973 6826 ...\n $ Sex                   : num [1:5649] 1 2 2 2 2 1 2 1 1 2 ...\n $ Age                   : num [1:5649] 10 10 10 9 10 10 9 9 10 10 ...\n $ Race_White            : num [1:5649] 1 1 0 0 0 0 1 1 1 1 ...\n $ Race_Black            : num [1:5649] 0 0 1 0 0 0 0 0 0 0 ...\n $ Race_Hispanic         : num [1:5649] 0 0 0 1 0 0 0 0 0 0 ...\n $ Race_Asian            : num [1:5649] 0 0 0 0 0 0 0 0 0 0 ...\n $ Race_Other            : num [1:5649] 0 0 0 0 1 1 0 0 0 0 ...\n $ ParentIncome          : num [1:5649] 5 6 999 4 1 6 7 8 9 7 ...\n $ ParentEducation       : num [1:5649] 13 15 13 13 11 12 19 21 18 18 ...\n $ IQ                    : num [1:5649] 51 40 52 40 36 49 999 63 19 44 ...\n $ FlankerTest           : num [1:5649] 52 51 40 39 44 34 999 40 30 38 ...\n $ PubertalDevelopment_F : num [1:5649] 3 999 999 999 999 999 999 1 4 999 ...\n $ PubertalDevelopment_M : num [1:5649] 999 2 3 1 3 999 2 999 999 2 ...\n $ MatureVideoGames      : num [1:5649] 1 1 2 1 2 1 1 1 1 1 ...\n $ Weekly_Gaming_Hours_T0: num [1:5649] 7 7 3.5 11 28 28 1.75 4.5 10.5 2.25 ...\n $ Weekly_Gaming_Hours_T1: num [1:5649] 7 9 28 28 4 3 7 7 8 9 ...\n $ Weekly_Gaming_Hours_T2: num [1:5649] 7 7 28 11 18 0 0 2 0 28 ...\n $ Aggression_T0         : num [1:5649] 0 15 5 2 14 17 0 5 0 5 ...\n $ Aggression_T1         : num [1:5649] 0 18 5 2 9 18 0 8 10 0 ...\n $ Aggression_T2         : num [1:5649] 999 20 9 3 8 999 0 999 6 1 ...\n $ Externalizing_T0      : num [1:5649] 1 18 7 2 20 21 0 7 0 5 ...\n $ Externalizing_T1      : num [1:5649] 1 22 10 2 12 25 0 10 12 0 ...\n $ Externalizing_T2      : num [1:5649] 999 25 14 3 11 999 0 999 7 1 ...\n $ Internalizing_T0      : num [1:5649] 1 5 6 4 2 17 0 5 4 4 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ids = col_character(),\n  ..   SiteID = col_double(),\n  ..   FamilyID = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Race_White = col_double(),\n  ..   Race_Black = col_double(),\n  ..   Race_Hispanic = col_double(),\n  ..   Race_Asian = col_double(),\n  ..   Race_Other = col_double(),\n  ..   ParentIncome = col_double(),\n  ..   ParentEducation = col_double(),\n  ..   IQ = col_double(),\n  ..   FlankerTest = col_double(),\n  ..   PubertalDevelopment_F = col_double(),\n  ..   PubertalDevelopment_M = col_double(),\n  ..   MatureVideoGames = col_double(),\n  ..   Weekly_Gaming_Hours_T0 = col_double(),\n  ..   Weekly_Gaming_Hours_T1 = col_double(),\n  ..   Weekly_Gaming_Hours_T2 = col_double(),\n  ..   Aggression_T0 = col_double(),\n  ..   Aggression_T1 = col_double(),\n  ..   Aggression_T2 = col_double(),\n  ..   Externalizing_T0 = col_double(),\n  ..   Externalizing_T1 = col_double(),\n  ..   Externalizing_T2 = col_double(),\n  ..   Internalizing_T0 = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nhist(df_wide$Externalizing_T0)\n\n\n\n# Compute difference score based on CBCL Externalizing subscale scores at baseline (t1) and 1-Year Follow-up (t2)\ndf_wide$diffscore = df_wide$Externalizing_T1 - df_wide$Externalizing_T0\n\n#Compute statistical summaries for the difference score variable\nsummary(df_wide$diffscore)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-998.000   -2.000    0.000    1.498    1.000  999.000 \n\n#Scatterplot to visualize relationship between t1 & t2 data used to create difference score\nscatterplot <- ggplot (df_wide, aes(x = Externalizing_T0, y = Externalizing_T1)) + geom_point(size = 3) + geom_smooth(method = lm, se = F) +\nxlab(\"CBCL Externalizing (x) Baseline\") +\nylab(\"CBCL Externalizing (x) 1-Year Follow-up\")\n\nsuppressWarnings(print(scatterplot))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n#One-sample t-test to determine whether the average difference score is significantly different than 0.\nresult <- t.test(df_wide$diffscore, mu = 0, alternative = \"two.sided\")\n# Print the results\nresult \n\n\n    One Sample t-test\n\ndata:  df_wide$diffscore\nt = 2.4509, df = 5648, p-value = 0.01428\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.2997325 2.6954879\nsample estimates:\nmean of x \n  1.49761 \n\n#boxplot\nlibrary(ggpubr)\ndiffscore_boxplot <- ggboxplot(df_wide$diffscore, \n          ylab = \"Externalizing Difference Score\", xlab = FALSE,\n          ggtheme = theme_minimal())\n\nsuppressWarnings(print(diffscore_boxplot))\n\n\n\n#Shapiro-Wilk test and normality (Q-Q) plot (visualization of correlation between a given sample and the normal distribution)\nshapiro.test(df_wide$diffscore[0:5000])\n\n\n    Shapiro-Wilk normality test\n\ndata:  df_wide$diffscore[0:5000]\nW = 0.057242, p-value < 2.2e-16\n\nlibrary(\"ggpubr\")\nqqplot <- ggqqplot(df_wide$diffscore, \n         ylab = \"Externalizing Difference Score\", xlab = FALSE,\n         ggtheme = theme_minimal())\n\nsuppressWarnings(print(qqplot))"
  },
  {
    "objectID": "Difference Scores_Main.html#explanation-of-model-code-plots",
    "href": "Difference Scores_Main.html#explanation-of-model-code-plots",
    "title": "1  Difference Scores",
    "section": "1.1 Explanation of Model Code & Plots",
    "text": "1.1 Explanation of Model Code & Plots\n\n1.1.1 Model code"
  },
  {
    "objectID": "Traditional Non-Linear Models.html",
    "href": "Traditional Non-Linear Models.html",
    "title": "book",
    "section": "",
    "text": "Traditional Non-Linear Models xxxx"
  },
  {
    "objectID": "Traditional Linear Models.html",
    "href": "Traditional Linear Models.html",
    "title": "book",
    "section": "",
    "text": "Traditional Linear Models xxxx"
  },
  {
    "objectID": "manuscript_working draft.html",
    "href": "manuscript_working draft.html",
    "title": "1  Manuscript",
    "section": "",
    "text": "2 Introduction\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper.\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, mo- lestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper.\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, mo- lestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper.\nMaecenas sed ultricies felis. Sed imperdiet dictum arcu a egestas.\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales com- modo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper.\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales com- modo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper.\n\\[E = m c^2 \\tag{4.1}\\]\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, mo- lestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper."
  },
  {
    "objectID": "manuscript_working draft.html#first-subsection",
    "href": "manuscript_working draft.html#first-subsection",
    "title": "1  Manuscript",
    "section": "5.1 First Subsection",
    "text": "5.1 First Subsection\nLorem ipsum dolor sit amet (CameronTrivedi2013?), consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales commodo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper."
  },
  {
    "objectID": "manuscript_working draft.html#second-subsection",
    "href": "manuscript_working draft.html#second-subsection",
    "title": "1  Manuscript",
    "section": "5.2 Second Subsection",
    "text": "5.2 Second Subsection\nLorem ipsum dolor sit amet, consectetuer adipiscing elit. Etiam lobortis facilisis sem. Nullam nec mi et neque pharetra sollicitudin. Praesent imperdiet mi nec ante. Donec ullamcorper, felis non sodales com- modo, lectus velit ultrices augue, a dignissim nibh lectus placerat pede. Vivamus nunc nunc, molestie ut, ultricies vel, semper in, velit. Ut porttitor. Praesent in sapien. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Duis fringilla tristique neque. Sed interdum libero ut metus. Pellentesque placerat. Nam rutrum augue a leo. Morbi sed elit sit amet ante lobortis sollicitudin. Praesent blandit blandit mauris. Praesent lectus tellus, aliquet aliquam, luctus a, egestas a, turpis. Mauris lacinia lorem sit amet ipsum. Nunc quis urna dictum turpis accumsan semper."
  },
  {
    "objectID": "Change Scores_Main.html#explanation-of-model-code-plots",
    "href": "Change Scores_Main.html#explanation-of-model-code-plots",
    "title": "2  Residual Change Scores",
    "section": "2.1 Explanation of Model Code & Plots",
    "text": "2.1 Explanation of Model Code & Plots\n\n2.1.1 Model code"
  },
  {
    "objectID": "LMM_Main.html#overview",
    "href": "LMM_Main.html#overview",
    "title": "9  Linear Mixed-Effects Models",
    "section": "9.1 Overview",
    "text": "9.1 Overview\nLinear mixed-effects models (LMM) are an extension of the General Linear Model (GLM) that allow for analyzing complex data including clustered observations and repeated measurements.\nLMMs offer a flexible framework for fitting longitudinal models and provide several benefits compared to traditional ANOVA and regression approaches. One particular advantage of the LMM framework is the ability to account for instances of non-independence among some subset(s) of observations in the data. A source of (non-indep?) common to longitudinal designs is data that is collected from the same participants at multiple measurement occasions. This introduces a correlated error structure into the data, violating the independence assumption–– a critical assumption of many statistical tests that indicates the observations in a data set must be independent; that is, they cannot be correlated with one another (see non-indep? section of more info on assumption of indepencence xxxxx).\nLMM explicitly account for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. Specifically, this approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory.\nIt is this “mixture” of fixed and random effects for which these models derive their name. In turn, LMMs provide better prediction, more precise and generalizable effect estimates, reduced Type I errors (i.e., false positives), and improved statistical power."
  },
  {
    "objectID": "LMM_Main.html#references",
    "href": "LMM_Main.html#references",
    "title": "9  Linear Mixed-Effects Models",
    "section": "9.2 References",
    "text": "9.2 References\n(brown2021?) \n\n Dealing with specificity\n\nThis is filler text <insert code> with the class."
  },
  {
    "objectID": "difference_scores_main.html#explanation-of-model-code-plots",
    "href": "difference_scores_main.html#explanation-of-model-code-plots",
    "title": "Difference Scores",
    "section": "Explanation of Model Code & Plots",
    "text": "Explanation of Model Code & Plots\n\nModel code"
  },
  {
    "objectID": "change_scores_main.html#explanation-of-model-code-plots",
    "href": "change_scores_main.html#explanation-of-model-code-plots",
    "title": "Change Scores",
    "section": "Explanation of Model Code & Plots",
    "text": "Explanation of Model Code & Plots\n\nModel code"
  },
  {
    "objectID": "paired_samples_t-test_main.html",
    "href": "paired_samples_t-test_main.html",
    "title": "2  Paired Sample T-test",
    "section": "",
    "text": "Paired Samples T-test"
  },
  {
    "objectID": "lmm_main.html#overview",
    "href": "lmm_main.html#overview",
    "title": "Linear Mixed Models",
    "section": "Overview",
    "text": "Overview\nLinear mixed-effects models (LMM) are an extension of the General Linear Model (GLM) that allow for analyzing complex data including clustered observations and repeated measurements.\nLMMs offer a flexible framework for fitting longitudinal models and provide several benefits compared to traditional ANOVA and regression approaches. One particular advantage of the LMM framework is the ability to account for instances of non-independence among some subset(s) of observations in the data. A source of (non-indep?) common to longitudinal designs is data that is collected from the same participants at multiple measurement occasions. This introduces a correlated error structure into the data, violating the independence assumption–– a critical assumption of many statistical tests that indicates the observations in a data set must be independent; that is, they cannot be correlated with one another (see non-indep? section of more info on assumption of indepencence xxxxx).\nLMM explicitly account for these dependencies among data by extending the general regression “fixed effects” model to allow both, fixed and random effects. Specifically, this approach simultaneously models an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory.\nIt is this “mixture” of fixed and random effects for which these models derive their name. In turn, LMMs provide better prediction, more precise and generalizable effect estimates, reduced Type I errors (i.e., false positives), and improved statistical power.\n\nBrief Overview\nCore assumptions of LMM is that the residuals and random effects are independent and identically distributed. This assumption states that the observations in a data set must be independent; that is, they cannot be correlated with one another. Violations of distributional assumptions introduce bias into the model and the impact of missing random effects components on model estimates leads to increased prediction error and attenuate overall model validity. As standard regression techniques (e.g., multiple regression) would violate the independence assumption, repeated measures ANOVA is commonly used for analyzing this type of data. However, xxxxxx.\nrepeated-measures pose a problem to most standard statistical procedures such as ordinary least-squares regression or (between-subjects) ANOVA as those procedures assume that the data points are independent and identically distributed (henceforth iid). The independence assumption states that the probability of a data point taking on a specific value is independent of the values taken by all other data points.\n\ncompared to violations of other assumptions, traditional statistical procedures are usually not robust to violations of the independence assumption (Judd et al., 2012; Kenny & Judd, 1986), which can lead to reduced standard errors and in turn, notable increases in Type I (false positives) errors, potentially biasing/skewing results positively.\n\n\n\nNormally distributed residuals\nxxxxxxx\n\n\nLinear Assocations\nLinear relationship between explanatory/predictor variables and the response variable.\n\n\nNon-Independnce\nThe assumption of non-independence asserts that observations in a dataset must be independent; that is, they cannot be correlated with one another. Unlike other assumptions, this one is important because xxxxxxxx not robust against xxxx it is. In longitudnal analyses, repeated observations from the same person are expected to be correlated–– that is, be more alike than two observations coming from two different participants–– and in turn, violate this assumption. THAT IS A participant’s rank in at one measurement occasion is predictive of their rank at another measurement occasion. Consider the hypothetical outlined above. When measuring response time across multiple measurement occasions, some individuals will generally demonstrate slower response times than others. That is, on average some participants will be slower than others (and vice-versa). The data points that reflect these response time values within a given individual will be correlated and non-independent. Compared to other model assumptions, standard statistical procedures are usually not robust to violations of the independence assumption (Judd et al., 2012; Kenny & Judd, 1986). Therefore, it is important that these data are analyzed using a statistical test that takes the dependencies in the data into account. [LMM fits this criteria by explicitly capturing the dependency among data points via inclusion of a [random effects] parameters].\nHere, statistical independence is defined in terms of conditional probabilities. That is, the assumption of independence does not pertain to individual’s actual data points, but rather is concerned with the residuals or errors ϵi (i.e., conditional distribution) after adjusting for the statistical model (e.g., fixed effects; random effects. Specifically, this assumption is considered to not be violated if the residuals are independent and identically distributed (IID), follow a normal distribution with a mean of 0 and a standard deviation σϵ. IID ensures that errors are independent when (P(x|θ)=P(x|θ,􏱂 x). i i j􏱁ij) “their distribution, conditional upon knowing the value of the predictors and the error of any other case, is the same as the distribution conditional upon just knowing the value of the predictors”. That is, for any observation i, the probability that it takes on a specific value xi is the same regardless of the values taken on by all the other observations j 􏱁 i, and a statistical model with parameter vector θ: (P(x|θ)=P(x|θ,􏱂 x). i i j􏱁ij). LMM accomplishes this by explicitly capturing the dependency among data points via inclusion of a [random effects] parameters.\n\n\nFixed vs Random Effects\nTraditional regression techniques estimate a group mean (fixed-effect) linear function to explain the relationship between a set of predictor values and an outcome. That is, the same regression line (both intercept and slope) is “fixed” to the group average trajectory for the entire sample. For example, in our hypothetical scenario, a traditional fixed-effects model estimates the mean intercept xx and slope xx of the reaction time trajectory. These analyses provides us information on the overall sample mean trajectory, such as xxxxxxx (see FIGURE X). LMM extends this traditional approach by simultaneously modeling an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about this average trajectory. In our hypothetical example, inclusion of a subject-specific random intercept allows each participant’s reaction time trajectory to deviate from the mean-level (fixed-effect) trajectory. These deviations (random-effects) are assumed to follow a normal distribution with a mean of zero and an estimated variance parameter.\nrepeated measures ANOVAs cannot simultaneously model between-person and within-person variability, so observations must be collapsed across xxxxx (groups or time?). However, aggregating data in this manner can be problematic as important information about variability within participants or conditions is lost. The results in a reduction of statistical power to detect true effects.\nThis model shares considerable (conceptual and statistical) overlap with a traditional regression approach. A standard linear regression models the average (fixed) trajectory for some repeatedly measured outcome by estimating mean intercept and slope parameter values.\nThis subject-specific (random) effect has a mean of zero and is normally distributed around the overall intercept (fixed effect) value.\nIn multiple regression, in contrast, the same regression line (both intercept and slope) is applied to all participants, so predictions tend to be less accurate than in mixed-effects regression, and residual error tends to be larger."
  },
  {
    "objectID": "lmm_main.html#references",
    "href": "lmm_main.html#references",
    "title": "Linear Mixed Models",
    "section": "References",
    "text": "References\n(brown2021?)"
  },
  {
    "objectID": "data_wrangling.html",
    "href": "data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "test"
  },
  {
    "objectID": "difference_scores_main.html#overview",
    "href": "difference_scores_main.html#overview",
    "title": "Difference Scores",
    "section": "Overview",
    "text": "Overview\nDifference scores (gain scores) are one of the earliest developed and most commonly used approaches for analyzing data collected across multiple measurement occasions (e.g., pre-test/post-test scores) (castro-schilo2018?; jennings2016?). This approach computes a raw difference score as an index change (\\(\\Delta\\)) in relation to some variable (\\(x\\)) by subtracting the variable’s value obtained at a prior measurement occasion (t1) from the value of the same variable obtained at a subsequent occasion (t2). This difference value (\\(\\Delta\\) = \\(x_{t2}\\) - \\(x_{t1}\\)) can then be used as the outcome in a GLM to test for differences in the amount of change over time and between groups of interest.\n\nModel AssumptionsNotes_TBD\n\n\ntest test\n\n\nSince the data being compared at exactly two points in time is paired (non-independent), the paired t-test analysis is appropriate. With the exception of this aspect of (non)independence in paired, longitudinal data, the underlying assumptions for this type of analysis are exactly the same as for the independent samples t-test:\nnon-independence means that a portion of the variance in the data is due to the individual differences that existed at the first point in time, not due to intervention-caused differences across the two points in time\nType of (Outcome) Variable: The scale of measurement for the dependent variable is continuous (interval). Normal Distribution: The dependent variable is normally distributed in the population, or a sufficiently large sample size was drawn to allow approximation of the normal distribution. Note: the “rule of thumb” is that neither group should be smaller than 6, and ideally has more. Independent Observations: Individuals within each sample and between the two groups are independent of each other—random selection indicates that the chances of any one “unit” being sampled are independent of the chances for any other being sampled. Homogeneity of Variance: Variance is the same for the two groups, as indicated by equal standard deviations in the two samples.\n\n\n\n\n test \n\n!Important Note. These models (t-test, ANOVA, and regression) are equivalent and all are subsumed by the GLM framework. More specifically, ANOVA is a special case of regression analysis where all the predictor variables are categorical. For the two-group case, the ANOVA model can be written as the following regression model \\(x_{t2}\\) - \\(x_{t1}\\)=\\(β_0\\) + \\(β_1\\) C + \\(\\epsilon\\) (\\(x_{t2}\\) - \\(x_{t1}\\)) where \\(x_{t2}\\) - \\(x_{t1}\\) is the difference between Time 2 (\\(_{t2}\\)) and Time 1 (\\(_{t1}\\)) scores, \\(β_0\\) is the intercept or average predicted value of the difference across time for individuals in group = 0, ’‘\\(β_1\\)’ is the regression coefficient for C indicating the difference in difference scores between between group = 0 and group = 1, and \\(\\epsilon\\)(\\(x_{t2}\\) - \\(x_{t1}\\)) is the residual (i.e., error) score (normally distributed with zero mean) that captures all other factors not accounted for by the grouping predictor. Typically, the effect of interest is “\\(β_1\\)”, which represents the difference between the average difference scores of the two groups. ___\n\n\nKey Considerations & Limitations + Imbalanced baseline scores + If baseline scores are imbalanced across groups, effect estimates of the mean difference score may become biased (via regression to the mean). This can lead individual studies to produce different conclusions regarding equivalent models. + Reliability and Stability + Increased stability (over time) can lead to decreased reliability of difference scores. That is, the stronger the Time 1–Time 2 correlation, the less variability in the difference score there is to detect (can’t predict/detect what’s not there). + See Cronbach and Furby (1970)(cronbach1970?); but also Jennings & Cribbie, 2016(jennings2016?); Rogosa, Brandt, & Zimowski, 1982(rogosa1982?); Wright, 2006(wright2006?) + Raw Scores + Prestandardizing variables discards important variance information and as such, raw scores should be used when computing difference scores + Types of change + A concern more broadly with studies that include only two measurement occasions is that only rank-order changes in levels of a variable can be measured (king2018?)."
  },
  {
    "objectID": "difference_scores_main.html",
    "href": "difference_scores_main.html",
    "title": "Difference Scores",
    "section": "",
    "text": "Model Assumptions\ntest test\nSince the data being compared at exactly two points in time is paired (non-independent), the paired t-test analysis is appropriate. With the exception of this aspect of (non)independence in paired, longitudinal data, the underlying assumptions for this type of analysis are exactly the same as for the independent samples t-test:\nnon-independence means that a portion of the variance in the data is due to the individual differences that existed at the first point in time, not due to intervention-caused differences across the two points in time\nType of (Outcome) Variable: The scale of measurement for the dependent variable is continuous (interval). Normal Distribution: The dependent variable is normally distributed in the population, or a sufficiently large sample size was drawn to allow approximation of the normal distribution. Note: the “rule of thumb” is that neither group should be smaller than 6, and ideally has more. Independent Observations: Individuals within each sample and between the two groups are independent of each other—random selection indicates that the chances of any one “unit” being sampled are independent of the chances for any other being sampled. Homogeneity of Variance: Variance is the same for the two groups, as indicated by equal standard deviations in the two samples.\n::: #::::"
  },
  {
    "objectID": "difference_scores_main.html#explanation",
    "href": "difference_scores_main.html#explanation",
    "title": "Difference Scores",
    "section": "Explanation",
    "text": "Explanation\n\nDifference Scores\nIn a repeated measures design, a difference score \\((\\Delta)\\) can be calculated by subtracting pairs of values on some variable (\\(x\\)) produced by the same individual across two (*or more) timepoints \\((x_{t1}, x_{t2})\\). First, compute the difference (\\(\\Delta\\)) between the score (\\(x\\)) obtained at baseline (\\(x_{t1}\\)) and follow-up (\\(x_{t2}\\)) for each individual (\\((\\Delta = x_{t2} − x_{t1})\\)). This difference value (\\(\\Delta\\) = \\(x_{t2}\\) - \\(x_{t1}\\)) can then be used as the outcome in a GLM to test for differences in the amount of change over time and between groups of interest.\nand divide by the sample size (n) to obtain the sample average of differences. (e.g., pre/post test scores)\n\n\nSingle-Group Repeated Measures Design:\nThe most basic repeated measures design the involves a single-group repeated measures design. In this design, we have n repeated measures of the response on each of N subjects.\n\n(Paired Samples T-test)\nThe paired samples (matched-pairs) t-test (t-testp) can be used to determine whether the difference between some pair of values (e.g., pre/post test scores) produced by the same individual across two measurement occasions, differs significantly from 0. The t-testp is a special case of the one-sample t-test, with the exception that this model needs to be modified to account for the statistical dependence among repeated observations obtained on the same subject, other than the issue of non-independence the underlying assumptions for the t-testp is exactly the same as for the independent samples t-test.\nTo compute the t-testp (\\((\\Delta = x_{t2} − x_{t1})\\)) the sample average of differences value obtained from the formula provided in step 1 (\\((\\Delta = x_{t2} − x_{t1})\\)) will be used as the numerator in your calculation of the t-value. The denominator in this computation is a variance estimate (i.e., the sample standard error), which accounts for the covariance between initial levels and change. A significant t-statistic indicates that change \\((\\Delta)\\) from T1 to T2 is significantly greater than 0.\n\nHypothetical Scenario: Table 1. Raw and difference scores before and after training.\n\nTable 1 shows scores on a quiz that five employees received before they took a training course and after they took the course. The difference between these scores (i.e. the score after minus the score before) represents improvement in the employees’ ability. This third column is what we look at when assessing whether or not our training was effective. We want to see positive scores, which indicate that the employees’ performance went up.\n\n\n(rANOVA)\nThe repeated-measures (within-subjects) ANOVA is an extension of the paired-samples t-test that is used to determine whether mean scores on some outcome measured at three or more occasions differs significantly across measurement occasions.\n\n\n\nBasic T-testp/ANOVA:\ncan be extended for multiple groups and 3+ timepoints 1) T-test/ANOVA: + A t-test can be performed using a grouping variable to examine whether the disparity in the mean difference value differs significantly between two groups. An ANOVA can be used if the grouping variable includes more than 2 groups.\nThe basic one-way repeated measure ANOVA can be extended (e.g., two-way, three-way) to evaluate whether or not a significant interaction effect exists between two or more factors (groups/levels) of some within-subjects variable.\n+ Example based on hypothetical \n    + First we compute the difference ($\\Delta$) between the score on the measure of screen time ($x$) assessed at baseline ($x_{t1}$) and follow-up ($x_{t2}$). \n    + The result of this formula ($\\Delta$=$x_{t2}$ - $x_{t1}$) can then be used as an outcome to test the effect of group on  the difference score ($\\Delta_{boys}$,  $\\Delta_{girls}$ ). \n    + Figure x.\n\nGLM Equation: \\(RS{_n}{_2} - RS{_n}{_1} = \\gamma_0 + \\gamma_1 Cn + e_{n(RS2-RS1)}\\)\n\nwhere RSn2 􏰫 RSn1 is the difference between Time 2 and Time 1 scores, g0 is the intercept or average predicted value of the difference across time in relationship satis- faction for those who did not cohabit prior to marriage (Cn 1⁄4 0), g1 is the regression coefficient for Cn indicating the difference in change between Time 1 and Time 2 between those who cohabited and those who did not, and en(RS2􏰫RS1) is the residual score that captures all other factors not accounted for by the cohabited predictor. Importantly, if the key predictor, Cn, was continuous (e.g., number of months couples lived together before marriage), the model in Equation 2 would no longer be called repeated measures ANOVA, but Sofia could compute the difference score variable herself and run a simple linear regression with Cn as the sole predictor to assess whether increases in time cohabiting prior to marriage predict change in relationship satisfaction.\n\nHypothetical Scenario: A study investigates sex differences on a measure of screen time by examining change in screen time scores obtained across two measurement occasions for boys and girls. The study aims to determine whether sex has an effect on changes in screen time across assessments.\n\n\n\nBasic Regression:\n\nRegression:\n\n\nA simple regression analysis can be performed using a grouping variable as a predictor of change (\\(\\Delta\\)) in an outcome across groups. A significant effect for the grouping variable indicates that average \\(\\Delta\\) is significantly different across groups.\n\nExample based on hypothetical\n\nFirst we compute the difference (\\(\\Delta\\)) between the score on the measure of screen time (\\(x\\)) assessed at baseline (\\(x_{t1}\\)) and follow-up (\\(x_{t2}\\)).\nThe result of this formula (\\(\\Delta\\)=\\(x_{t2}\\) - \\(x_{t1}\\)) can be included as the outcome variable in a regression model that analyzes the role of the grouping variable (0 = boy; 1 = girl) on changes in screen time across measurement occassions.\n\nFigure x. :::"
  },
  {
    "objectID": "change_scores_main.html#overview",
    "href": "change_scores_main.html#overview",
    "title": "Change Scores",
    "section": "Overview",
    "text": "Overview\nThis approach estimates a regression coefficient as an index change (\\(\\Delta\\)) in relation to some variable (\\(x\\)) by regressing the variable’s value obtained at a follow-up measurement occasion (t2) on the value of the same variable obtained at a prior (e.g., baseline) occasion (t1). This estimated score (\\(\\Delta\\)= \\(x_{t2}\\) adjusts for baseline scores while ignoring any group assignment. A common step 2 is for this \\(\\Delta\\)= \\(x_{t2}\\) to be included in subsequent analysis, such as an examination of pre/post intervention effects (Kisbu-Sakarya et al., 2013).\nˆ RES\n\nBrief Overview\nSince the data being compared at exactly two points in time is paired (non-independent), the paired t-test analysis is appropriate. With the exception of this aspect of (non)independence in paired, longitudinal data, the underlying assumptions for this type of analysis are exactly the same as for the independent samples t-test:\nnon-independence means that a portion of the variance in the data is due to the individual differences that existed at the first point in time, not due to intervention-caused differences across the two points in time\nType of (Outcome) Variable: The scale of measurement for the dependent variable is continuous (interval). Normal Distribution: The dependent variable is normally distributed in the population, or a sufficiently large sample size was drawn to allow approximation of the normal distribution. Note: the “rule of thumb” is that neither group should be smaller than 6, and ideally has more. Independent Observations: Individuals within each sample and between the two groups are independent of each other—random selection indicates that the chances of any one “unit” being sampled are independent of the chances for any other being sampled. Homogeneity of Variance: Variance is the same for the two groups, as indicated by equal standard deviations in the two samples.\n\n!Important Note. These models (t-test, ANOVA, and regression) are equivalent and all are subsumed by the GLM framework. More specifically, ANOVA is a special case of regression analysis where all the predictor variables are categorical. For the two-group case, the ANOVA model can be written as the following regression model \\(x_{t2}\\) - \\(x_{t1}\\)=\\(β_0\\) + \\(β_1\\) C + \\(\\epsilon\\) (\\(x_{t2}\\) - \\(x_{t1}\\)) where \\(x_{t2}\\) - \\(x_{t1}\\) is the difference between Time 2 (\\(_{t2}\\)) and Time 1 (\\(_{t1}\\)) scores, \\(β_0\\) is the intercept or average predicted value of the difference across time for individuals in group = 0, ’‘\\(β_1\\)’ is the regression coefficient for C indicating the difference in difference scores between between group = 0 and group = 1, and \\(\\epsilon\\)(\\(x_{t2}\\) - \\(x_{t1}\\)) is the residual (i.e., error) score (normally distributed with zero mean) that captures all other factors not accounted for by the grouping predictor. Typically, the effect of interest is “\\(β_1\\)”, which represents the difference between the average difference scores of the two groups. ___\n\n\nKey Considerations & Limitations + Imbalanced baseline scores + If baseline scores are imbalanced across groups, effect estimates of the mean difference score may become biased (via regression to the mean). This can lead individual studies to produce different conclusions regarding equivalent models. + Reliability and Stability + Increased stability (over time) can lead to decreased reliability of difference scores. That is, the stronger the Time 1–Time 2 correlation, the less variability in the difference score there is to detect (can’t predict/detect what’s not there). + See Cronbach and Furby (1970)(cronbach1970?); but also Jennings & Cribbie, 2016(jennings2016?); Rogosa, Brandt, & Zimowski, 1982(rogosa1982?); Wright, 2006(wright2006?) + Raw Scores + Prestandardizing variables discards important variance information and as such, raw scores should be used when computing difference scores + Types of change + A concern more broadly with studies that include only two measurement occasions is that only rank-order changes in levels of a variable can be measured (king2018?)."
  },
  {
    "objectID": "change_scores_main.html#explanation",
    "href": "change_scores_main.html#explanation",
    "title": "Change Scores",
    "section": "Explanation",
    "text": "Explanation\n\nChange Scores\nIn a repeated measures design, a residualized change score \\((\\Delta\\RES)\\) can be calculated by regressing scores on some variable (\\(x\\)) produced by the same individual at a follow-up occassion (t2) on their score on that variable at a prior occassion (t1) \\((x_{t1}, x_{t2})\\). This residuals computed by this approach do not adjust for any a prior group differences.This residualized change score (\\(\\Delta\\) = \\(x_{t2}\\) regressed on \\(x_{t1}\\)) is then often piped into a second step where it is used as the outcome in subsequent GLM analyses, for example, in a standard two-sample t-test to compare the change score value between groups of interest (e.g., tx vs control groups).\n\n\nSingle-Group Repeated Measures Design:\nThe most basic repeated measures design the involves a single-group measured across two occassions.\n\nHypothetical Scenario: Table 1. Residualized change score based on pre- and post-test scores.\n\nTable 1 shows scores on a quiz that five participants received on an xxxx pre-test and then at a follow-up xxxxxx. Regressing the t2 score on the t1 score represents the estimated change in scores over time. The resulting regression coefficient can be subtracted from each particpants observed score at T2 to examine whether particpiants scores went up (positive values of x) or down (negative values of x) across the two measurement occassions.\n\n\nBasic ANOVA:\n\nT-test/ANOVA:\n\n\nA t-test can be performed using a grouping variable to examine whether the disparity in the residualized change score differs significantly between two groups. The repeated-measures (within-subjects) ANOVA is an extension of the paired-samples t-test that is used to determine whether mean scores on some outcome measured at three or more occasions differs significantly across measurement occasions. The residual change score method (ANOVA on the residual scores) can be expressed as Yi,adjusted = β0 + β1,Groupi + ei, (4) where Yi,adjusted = Yi − Yˆ(= γ0 + γ1Xi). This model evaluates whether there are significant gorup differences on the residual change score, conditional on the pre-test scores where the conditioning occurs in the absence of group membership. This method is similar to an ANCOVA approach in that both models statistically adjust for pre-test (t1) scores. However, the change score model does not adjust for any potential group effects at baseline (i.e., the dervied regression coefficient are based on the total sample), whereas the ANCOVA model includes the pooled within slope, across groups (Jenningsetal2016?; Kisbu-Sakarya2013?).\n\n\nHypothetical Scenario: A study investigates sex differences on a measure of screen time by examining change in screen time scores obtained across two measurement occasions for boys and girls. The study aims to determine whether sex has an effect on changes in screen time across assessments. + Example based on hypothetical + First we compute the residual change score (\\(\\Delta\\)) by regressing the score on the measure of screen time (\\(x\\)) assessed at follow-up (\\(x_{t2}\\)) and on the score measured at baseline (\\(x_{t1}\\)). + The result of this formula (\\(\\Delta\\)=\\(x_{t2}\\) regressed on \\(x_{t1}\\)) can then be used as an outcome to test the effect of group on the residualized change score (\\(\\Delta_{boys}\\), \\(\\Delta_{girls}\\) ). + Figure x.\n\n\n\nBasic Regression:\n\nRegression:\n\n\nA simple regression analysis can be performed using a grouping variable as a predictor of change (\\(\\Delta\\)) in an outcome across groups. A significant effect for the grouping variable indicates that average \\(\\Delta\\) is significantly different across groups.\n\n\nHypothetical Scenario: A study investigates sex differences on a measure of screen time by examining change in screen time scores obtained across two measurement occasions for boys and girls. The study aims to determine whether sex has an effect on changes in screen time across assessments.\n\n+ Example based on hypothetical\n    + First we compute the difference ($\\Delta$) between the score on the measure of screen time ($x$) assessed at baseline ($x_{t1}$) and follow-up ($x_{t2}$). \n    + The result of this formula ($\\Delta$=$x_{t2}$ - $x_{t1}$) can be included as the outcome variable in a regression model that analyzes the role of the grouping variable (0 = boy; 1 = girl) on changes in screen time across measurement occassions.\n+ Figure x."
  },
  {
    "objectID": "lmm_main.html#explanation",
    "href": "lmm_main.html#explanation",
    "title": "Linear Mixed Models",
    "section": "Explanation",
    "text": "Explanation\n\nLinear Mixed Model with Random Intercept:\nThe random intercept LMM is similar (conceptually and statistically) to traditional (fixed-effect) linear regression. A key difference is that random intercept LMM extends the traditional fixed-effects approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value. More formally: \\[\n{Y} = b_{intercept} + b_{time}⋅time + \\epsilon\n\\tag{1}\\]\nA standard linear fixed-effects regression model includes coefficients (\\(b\\)) for the model intercept and the effect of time. The error term (\\(\\epsilon\\)) is assumed to be normally distributed with a mean of zero and a standard deviation (\\(\\sigma\\)). A random intercept LMM extends the standard fixed effects regression by including subject-specific random-effect for each participant. The random-effect is assumed to be normally distributed with a mean of zero and a standard deviation (\\(\\sigma\\)).\n\\[\n{Y}  = b_{intercept} + b_{time}⋅time + (effect_{subject}+\\epsilon)\n\\]\nThis equation can be rearranged such that the random-effect estimates subject-specific intercepts that are unique to each participant. This allows the model to simultaneously estimate 1) a fixed-intercept coefficient that represents the sample average intercept value; and 2) a random-effects variance parameter that allows each participant to have their own unique intercept that deviates from the average intercept value.\n\\[\n{Y}  = (b_{intercept} + effect_{subject}) + b_{time}⋅time + \\epsilon\n\\]\nHypothetical Scenario: A study investigates trajectories of scores on a measure of happiness obtained across five measurement occasions in a sample of youth (i.e., repeated observations are clustered within participants). The study aims to characterize stability and change in happiness across assessments, while accounting for observations that are clustered within youth over time.\n\n\nThe overall group-mean (fixed effects) trajectory is shown in blue. The faded lines represent each individual youth’s estimated trajectory. An examination of this figure shows happiness scores to be increasing across measurement occasions, however, there appears to be substantial variability in the youth’s initial happiness scores.\n\n\n\nLinear Mixed Model with Random Intercepts & Slopes\nExtending the random intercept LMM to include a subject-specific random-slope parameter allows each participant to have their own unique intercept & slope value. Relative to intercept-only LMM, this model estimates an addtional variance parameter that captures each participant’s variability around the overall mean-level (fixed-effect) slope value. More formally: \\[\n{Y} = (b_{intercept} + effect_{subject}) + (b_{time}⋅time + effect_{subject} +\\epsilon)\n\\]\nA random intercept and slope LMM extends the intercept-only model by also including a subject-specific random-effect for each participant's slope value.This model simultaneously estimates 1) a fixed-intercept coefficient that represents the sample average intercept value; and 2) a random-effect (i.e., variance parameter around the intercept) that allows each participant to have their own unique intercept that deviates from the average intercept value; 3) a random-effect (i.e., variance parameter around the slope) that allows each participant to have their own unique slope that deviates from the average slope value\n\n Hypothetical Scenario: A study investigates trajectories of scores on a measure of happiness obtained across five measurement occasions in a sample of youth (i.e., repeated observations are clustered within participants). The study aims to characterize stability and change in happiness across assessments, while accounting for observations that are clustered within youth over time.\n\n\nThe overall group-mean (fixed effects) trajectory is shown in blue. The faded lines represent each individual youth’s estimated trajectory. An examination of this figure shows happiness scores to be increasing across measurement occasions, however, there appears to be substantial variability in the youth’s initial happiness scores and in how these scores change across measurement occasions."
  },
  {
    "objectID": "manuscript_working_draft.html",
    "href": "manuscript_working_draft.html",
    "title": "1  Biostats WG Manuscript",
    "section": "",
    "text": "2 Introduction\nThe Adolescent Brain Cognitive DevelopmentSM (ABCD) Study is the largest long-term investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental influences on brain development and their roles in behavioral and health outcomes in adolescents (volkow2018?). At its heart, the study is designed to chart the course of human development across multiple, interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative developmental outcomes. Central to achieving these goals is the ABCD Study’s® committement to an open science framework designed to facilitate access to and sharing of scientific knowledge by espousing practices that increase openness, integrity, and reproducibility of scientific research (e.g., public data releases). In this sense, the ABCD Study® is a collaboration with the larger research community, with the rich longitudinal nature of the ABCD Study dataset allowing researchers to perform a variety of analyses of both methodological and substantive interest. Together, this presents a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes emerge and unfold across critical periods of development.\nThere are a number of important concepts to consider when conducting longitudinal analyses in a developmental context. These include different ways of thinking about developmental course, whether certain periods of development are relatively sensitive or insensitive to various types of insults or stressors, whether some time periods or situations inhibit the expression of individual differences due to extreme environmental pressures, and whether the same behavior manifested at different times represent the same phenomenon or different ones. Further, in the case of developmentally focused longitudinal research, each new measurement occasion not only provides a more extended portrait of the child’s life course (and not just characterize growth during this period but also assess the durability/chronicity of prior effects/consequences), but also brings with it greater methodological opportunities to exploit the statistical properties of longitudinal data in the furtherance of critical scientific questions. That is, we can ask more nuanced questions and make stronger inferences as our number of time-ordered observations grow, assuming we have assessed the “right” variables and the timings of our observations comport with the temporal dynamics of the mechanisms of interest. Appreciation of these and other issues can help to guide analysis and interpretation of data and aid translation to clinical and public health applications.\n ## Vulnerable periods Development normatively progresses from less mature to more mature levels of functioning. However, unique epochs and experiences can alter the course of this idealized form of development. Consider research that shows cannabis use during adolescence is associated with later psychosis to a greater degree than cannabis use initiated later in development (xxxx?); or, similarly, experimental research on rodents that shows rodent brains to be especially sensitive to the neurotoxic effects of alcohol on brain structure and learning early in development (corresponding to early adolescence in humans)(xxxx?). These examples highlight the importance of considering the role of vulnerable periods – temporal windows of rapid brain development or remodeling during which the effects of environmental stimuli (e.g. cannabis exposure) on the developing brain may be particularly pronounced– when trying to establish an accurate understanding of the association between exposures and outcomes.  ## Developmental disturbances Whereas vulnerable periods heighten neurobiological susceptibility to environmental influences, at other times environmental pressures will tend to suppress stability and disrupt the orderly stochastic process of normative development (e.g., xxxxxx). This situation reflects a developmental disturbance in that the normal course of development is “disturbed” for a period of time by some time-limited process. In such cases, we might find that prediction of behavior in the period of the disturbance is reduced and/or, similarly, behavior exhibited during the disturbance might have less predictive power with respect to distal outcomes compared to behavior exhibited prior to and following the disrupted period. That is, once the environmental stimuli is removed (or the individual is removed from the environment) individual differences are again more freely expressed and the autoregressive effects increase to levels similar to those prior to entering the environment.  ## Developmental snares and cascade effects Normative development can also be upended by experiences (e.g., drug use) that, through various mechanisms, disrupts the normal flow of development wherein each stage establishes a platform for the next. For example, substance use could lead to association with deviant peers, precluding opportunities for learning various adapative skills and prosocial behaviors, in effect, creating a “snare” that retards psychosocial development. Relatedly, the consequences of these types of events can cascade (e.g.,. school dropout, involvement in the criminal justice system) so that the effects of the snare are amplified. Although conceptually distinct from vulnerable periods, both of these types of developmental considerations highlight the importance of viewing behavior in the context of development and the importance of attempting to determine how various developmental pathways unfold.  ### Distinguishing developmental change from experience effects One can often observe systematic changes over time in a variable of interest and assume this change is attributable to development. For example, cognitive abilities (e.g, verbal ability, problem solving) normatively grow earlier in development and often decline in late life (e.g., memory, speed of processing). However, the observed patterns of growth and decline often differ between cross-sectional vs. longitudinal effects (salthouse2014?) where subjects gain increasing experience with the assessment with each successive measurement occasion. Such experience effects on cognitive functioning have been demonstrated in adolescent longitudinal samples similar to ABCD (sullivan2017?) and highlight the need to consider these effects and address them analytically. In the case of performance-based measures [e.g., matrix reasoning related to neurocognitive functioning; see (salthouse2014?)], this can be due to “learning” the task from previous test administrations (e.g., someone taking the test a second time performs better than they did the first time simply as a function of having taken it before). Even in the case of non-performance-based measures (e.g., levels of depression), where one cannot easily make the argument that one has acquired some task-specific skill through learning, it has been observed that respondents tend to endorse lower levels on subsequent assessments (e.g., beck1961?; see french2010a?) and this phenomenon has been well documented in research on structured diagnostic interviews (robins1985?). While it is typically assumed that individuals are rescinding or telling us less information on follow-up interviews, there is reason to suspect that in some cases the initial assessment may be artefactually elevated (see shrout2018a?). Some designs (specifically, accelerated longitudinal designs) are especially well suited for discovering these effects and modelling them. While ABCD was not designed as an accelerated longitudinal design, the variability in age at the time of baseline recruitment (9 years, 0 months to 10 years, 11 months) allows some measures, collected on a yearly basis, to be conceptualized as an accelerated longitudinal design. Moreover, it is possible that in later waves, patterns of longitudinal missing data will allow some analyses to assess the confounded effects of age and number of prior assessments. However, ABCD is fundamentally a single-cohort, longitudinal design, where number of prior assessments and age are highly confounded and for, perhaps, most analyses, the possible influence of experience effects need to be kept in mind. |  # Part II Longitudinal Data: Interpretation / Issues / Pitfalls & Assumption ## Defining Features of Longitudinal Data Analysis (section intro) The hallmark characteristic of longitudinal data analysis is its application to repeated assessments of the same assessment targets (e.g., individuals, families) across time.\nWhile the primary reason for collecting longitudinal data is in pursuit of addressing scientific questions, from a methodological perspective, having multiple observations over time allows researchers to identify potentially problematic observations when highly improbable longitudinal patterns are observed.\nThat is, we can ask more nuanced questions and make stronger inferences as our number of time-ordered observations grow assuming we have assessed the “right” variables and the timings of our observations comport with the temporal dynamics of the mechanisms of interest."
  },
  {
    "objectID": "manuscript_working_draft.html#the-abcd-study-data",
    "href": "manuscript_working_draft.html#the-abcd-study-data",
    "title": "1  Biostats WG Manuscript",
    "section": "2.1 The ABCD Study® Data",
    "text": "2.1 The ABCD Study® Data\nA total cohort of \\(n = 11880\\) US children aged 9-10 years at baseline (born between 2006-2008) and their parents/guardians was recruited from 22 sites (with one site no longer active). Eligible children were recruited from the household populations in defined catchment areas for each of the study sites during the roughly two-year period beginning September 2016 and ending in October 2018.(Information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at the ABCD Study website.\nThe ABCD Study is collecting longitudinal data on a rich variety of outcomes that that will enable the construction of realistically-complex etiological models by incorporating factors from many domains simultaneously. Each new wave of data collection provides the building blocks for conducting probing longitudinal analyses that allow us to characterize normative development, identify variables that presage deviations from prototypic development, and assess a range of outcomes associated with variables of interest. This data includes a neurocognitive battery (luciana2018a?; thompson2019?), mental and physical health assessments (barch2018?), measures of culture and environment (zucker2018?), substance use (xxxxx?), biospecimens (uban2018?), structural and functional brain imaging (casey2018?; hagler2019?), geolocation-based environmental exposure data, wearables and mobile technology (bagot2018?), and whole genome genotyping (loughnan2020?). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and at every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits. Data are publicly released on an annual basis through the NIMH Data Archive NIMH Data Archive; NDA. By necessity, the study’s earliest data releases were cross-sectional (i.e., the baseline data), however, the most recent public data release (NDA Release 4.0) contains data collected across three annual assessments, including two imaging assessments (baseline and year 2 follow-up visits)."
  },
  {
    "objectID": "manuscript_working_draft.html#organization-of-current-manuscript",
    "href": "manuscript_working_draft.html#organization-of-current-manuscript",
    "title": "1  Biostats WG Manuscript",
    "section": "2.2 Organization of current manuscript",
    "text": "2.2 Organization of current manuscript\nThe rich longitudinal nature of the ABCD Study dataset will allow researchers to perform a number of analyses of both methodological and substantive interest. This report describes methods for longitudinal analyses of ABCD Study data that can address its fundamental scientific aims, as well as challenges inherent in a large population-based long-term study of adolescents. The manuscript is organized as follows: xxxxxxxxx."
  },
  {
    "objectID": "manuscript_working_draft.html#modeling-data-across-two-time-points-versus-three-or-more-time-points",
    "href": "manuscript_working_draft.html#modeling-data-across-two-time-points-versus-three-or-more-time-points",
    "title": "1  Biostats WG Manuscript",
    "section": "3.1 Modeling Data Across Two Time Points versus Three or More Time Points",
    "text": "3.1 Modeling Data Across Two Time Points versus Three or More Time Points\nAlthough the clear leap to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when experimental manipulation is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, data based on two assessments are inherently limited on multiple fronts. As (rogosa1982?) noted approximately forty years ago, “Two waves of data are better than one, but maybe not much better”. These sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for model identification and accurate parameter estimation. For example, (duncan2009?) recommend that developmental studies include three or more assessment points, given it is impossible for data based on two time points to determine the shape of development (since linear, straight line change is the only possible form, given two assessments). Research designs that include three or more time points allow for increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (king2018?)– a key aspect of inferential research. For example, developmental theories are typically interested in understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person-level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” (littlefield2021?). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability [e.g., the Latent Curve Model with Structured Residuals; (curran2014a?)] require at least four assessments to parameterize fully and, more generally, increasingly accurate parameter estimates are obtained as more assessment occasions are used (duncan2009?)."
  },
  {
    "objectID": "manuscript_working_draft.html#types-of-stability-and-change",
    "href": "manuscript_working_draft.html#types-of-stability-and-change",
    "title": "1  Biostats WG Manuscript",
    "section": "3.2 Types of stability and change",
    "text": "3.2 Types of stability and change\n(request permission to adapt King et al. (2018), Table 1) If one were to try to sum up what development in a living organism is exactly, one could plausibly argue it’s the characterization of stability and change as the organism traverses the life course. There are a few different ways to think of stability (and change). Consider we measure the height of all youth in a 6th grade class, once in the fall at the beginning of the school year and once again in the spring at the end of the school year. A common first step may be to compare the class’s average height values obtained at these two different measurement occasions. This comparison of the average scores for the same group of individuals between different time points is referred to as “mean-level” stability as it provides information about continuity and change in the group level of an outcome of interest (e.g., height) over time. Another type of stability involves calculating the correlation between the values obtained at different time points (e.g., ‘height in the fall’ with ‘height in the spring’). This type of “rank-order” stability evaluates between-individual change by focusing on the degree to which an individuals retain their relative placement in a group across time. For example, someone who is the shortest person in his class in 6th grade may grow considerably over the school year (i.e., exhibit mean level change), but still remain the shortest person among his classmates. That is, he is manifesting a type of rank order stability. Both types of stability and change are important. For example, mean-level change in certain traits might help to explain why, in general, individuals are particularly vulnerable to social influences at some ages more than others; rank order change might help to quantify the extent to which certain characteristics of the individual are more trait-like. For example, in some areas of development, there is considerable mean change that occurs over time (e.g., changes in Big 5 personality traits), but relatively high rank-order stability. Despite the useful information afforded by examining mean-level and rank-order change, these approaches are limited in that they provide little information about patterns of “within-individual” change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest.\nThere is a growing recognition that statistical models commonly applied to longitudinal data often fail to comport with the developmental theory they are being used to assess (e.g., Curran, Lee, Howard, Lane, & MacCallum, 2012; Hoffman, 2015; Littliefeld et al., 2021; xxxxx et al. (xxxx). Specifically, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person (i.e., intraindividual) processes (e.g., how phenotypes change or remain stable within individuals over time) (e.g., see curran2011?). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. As a result, experts increasingly caution of the need to xxxxxxxx (xxxxx?). Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see littlefield2021?; orth2021?). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., RI-CLPM, hamaker2015?; LCM-SR, curran2014a?). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see littlefield2021?, for further discussion)."
  },
  {
    "objectID": "manuscript_working_draft.html#model-assumptions",
    "href": "manuscript_working_draft.html#model-assumptions",
    "title": "1  Biostats WG Manuscript",
    "section": "3.3 Model Assumptions",
    "text": "3.3 Model Assumptions\n(*include table/figure that matches analyses & assumptions) Many statistical models assume some certain characteristics about the data to which they are being applied. For example, common assumptions of parametric statistical models include normality, linearity, and equality of variances. These assumptions must be carefully considered prior to conducting analysis so that valid inferences can be made from the data; that is, violation of a model’s assumptions can substantively alter interpretation of results. Similarly, statistical models employed in the analyses of longitudinal data often entail a range of assumptions that must be closely inspected. One central issue for repeated measurements on an individual is how to account for the correlated nature of the data; another common feature of longitudinal data is heterogeneous variability; that is, the variance of the response changes over the duration of the study. Traditional techniques, such as a standard regression or ANOVA model, assumes residuals are independent and thus are inappropriate for designs that assess (for example) the same individuals across time. That is, given the residuals are no longer independent, the standard errors from the models are biased and can produce misleading inferential results. Although there are formal tests of independence for time series data (e.g., the Durbin-Watson statistic; Durbin & Watson, 1950), more commonly independence is assumed to be violated in study designs with repeated assessments. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model the [covariance structure] (insert link) of said data."
  },
  {
    "objectID": "manuscript_working_draft.html#covariance-structures",
    "href": "manuscript_working_draft.html#covariance-structures",
    "title": "1  Biostats WG Manuscript",
    "section": "3.4 Covariance Structures",
    "text": "3.4 Covariance Structures\nStatistical models for longitudinal data include two main components to account for assumptions that are commonly violated when working with repeated measures data: a model for the covariance among repeated measures (both the correlations among pairs of repeated measures on an individual and the variability of the responses on different occasions), coupled with a model for the mean response and its dependence on covariates (eg, treatment group in the context of clinical trials). This allows for the specification of a range of so-called covariance structures, each with its own set of tradeoffs between model fit and parsimony (e.g., see kincaid2005?)."
  },
  {
    "objectID": "manuscript_working_draft.html#accounting-for-correlated-data",
    "href": "manuscript_working_draft.html#accounting-for-correlated-data",
    "title": "1  Biostats WG Manuscript",
    "section": "3.5 Accounting for Correlated Data",
    "text": "3.5 Accounting for Correlated Data\nAs an example, one alternative structure that attempts to handle the reality that correlations between repeated assessments tend to diminish across time is the autoregressive design. As the name implies, the structure assumes a subsequent measurement occasion (e.g., assessment at Wave 2) is regressed onto (that is, is predicted by) a prior measurement occasion (e.g., assessment at Wave 1). The most common type of autoregressive design is the AR(1), where assessments at time T + 1 are regressed on assessments at Time T. Identical to compound symmetry, this model assumes the variances are homogenous across time. Diverting from compound symmetry, this model assumes the correlations between repeated assessments decline exponentially across time rather than remaining constant. For example, per the AR(1) structure, if the correlation between Time 1 and Time 2 data is thought to be .5, then the correlation between Time 1 and Time 3 data would be assumed to be .5*.5 = .25, and the correlation between Time 1 and Time 4 data would be assumed to be .5*.5*.5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters (the variance of the assessments and the autoregressive coefficient). Notably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., cross-lagged panel models [CLPM]). These designs still typically assume an AR(1) process (e.g., it is sufficient to regress the Time 3 assessment onto the Time 2 assessment and is not necessary to also regress the Time 3 assessment onto the Time 1 assessments, which would result in an AR(2) process). However, the magnitude of these relations are often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between Time 1 and Time 2 can be different than the relation between Time 2 and Time 3). These more commonly employed models also often relax the assumption of equal variances of the repeated assessments. Although the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then autoregressive relations fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (hamaker2015?)."
  },
  {
    "objectID": "manuscript_working_draft.html#linear-vs-non-linear-models",
    "href": "manuscript_working_draft.html#linear-vs-non-linear-models",
    "title": "1  Biostats WG Manuscript",
    "section": "3.6 Linear vs non-linear models",
    "text": "3.6 Linear vs non-linear models\nIdentification of optimal statistcal models and appropriate mathematical functions requires an understanding of the type of data being used. Repeated assessments can be based on either continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across a ten-year period), ordinal variables (e.g., a single item measuring level of agreement to a statement on a three-point scale including the categories of “disagree”, “neutral”, and “agree” in an ecological momentary assessment study that involves multiple daily assessments), and count variables (e.g., number of cigarettes smoked per day across a daily diary study). In many ways, the distributional assumptions of indicators used in longitudinal designs mirrors the decisions points and considerations when delineating across different types of discrete outcome variables, a topic which spans entire textbooks (e.g., see lenz2016a?). For example, the Mplus manual (muthen2017?) includes examples of: a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, d) linear growth models for a count outcome assuming a zero-inflated Poisson model, and e) discrete- and continuous-time survival analysis for a binary outcome. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data. These models can account for issues that can occur when working with discrete outcomes, including overdispersion (when the variance is higher than would be expected based on a given distribution) and zero-inflation [when more zeros occur than is expected based on a given distribution; see (lenz2016?)]. Models involving zero-inflation parameters are referred to as two-part models, given one part of the model predicts the zero-inflation whereas the other part of the model predicts outcomes consistent with a given distribution [e.g., Poisson distribution; see (farewell2017?), for a review of two-part models for longitudinal data]. Although there exist several alternative models for discrete indicators, some more recent models that have been proposed for prospective data are only feasible in cases where indicators are assumed to be continuous rather than discrete [e.g., latent curve models with structured residuals; (curran2014?)]. Given the sheer breadth of issues relevant to determining better models for discrete outcomes, it is not uncommon for texts on longitudinal data analysis to only cover models and approaches that assume continuous indicators (e.g., little2013?). However, some textbooks on categorical data analysis provide more in-detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes [e.g., (lenz2016?), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes]."
  },
  {
    "objectID": "manuscript_working_draft.html#missing-dataattrition",
    "href": "manuscript_working_draft.html#missing-dataattrition",
    "title": "1  Biostats WG Manuscript",
    "section": "3.7 Missing Data/Attrition",
    "text": "3.7 Missing Data/Attrition\nAs recently reviewed by Littlefield (in press), investigators of prospective data are confronted with study attrition (i.e., participants may not provide data at a given wave of assessment) and thus approaches are needed to confront the issue of missing data. Three models of missingness are typically considered in the literature (see little1989?) . These three models are data: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR means missing data is a random sample of all the types of participants (e.g., males) in a given dataset . MAR suggests conditionally missing at random (see graham2009?). That is, MAR implies missingness is completely random (i.e., does not hinge on some unmeasured variables) once missingness has been adjusted by all available variables in a dataset (e.g., biological sex) . Data thar are MNAR are missing as a function of unobserved variables . (graham2009?) provides an excellent and easy to digest overview of further details involving missing data considerations.\nThere are multiple approaches that have been posited to handle missing dat a. Before the advent of more contemporary approaches, common methods included several ad hoc procedure s. These include eliminating the data of participants with missing data (e.g., listwise or pairwise deletion) or using mean imputation (i.e., replacing the missing value with the mean score of the sample that did participate ). However, these methods are not recommended because they can contribute to biased parameter estimates and research conclusions (see graham2009?). For example, last observation carried forward (LOCF) is a common approach to imputing missing data. LOCF replaces a participant’s missing values after dropout with the last available measurement (molnar2008?). This approach assumes stability (i.e., a given participants score is not anticipated to increase or decline after study drop out) and that the data are MCA R. However, as described by (molnar2008?), it is common for treatment groups to show higher attrition compared to control groups in studies of dementia drug s. Given dementia worsens across time, using LOCF biases the results in favor of the treatment group (see molnar2008?, for more details).\nMore modern approaches, such as using maximum likelihood or multiple imputation to estimate missing data, are thought to avoid some of the biases of the older approaches (see enders2010?; graham2009?). (graham2009?) noted several “myths” regarding missing da ta. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case dat a). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older metho ds. Graham thus suggests that estimating missing data is a better approach compared to the older procedures in most circumstances, regardless of the model of missingness [i.e., MCAR, MAR, MNAR; see (graham2009?)].\nAttrition from a longitudinal panel study such as ABCD is inevitable and represents a threat to the validity of longitudinal analyses and cross-sectional analyses conducted at later time points, especially since attrition can only be expected to grow over time. While, to date, attrition in ABCD has been minimal (some cite here), it remains an important focus for longitudinal analysis and its significance is likely to only grow as the cohort ages. Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (cotter2005?; hill2016?; watson2018?). However, even the best executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies design to provide the most valid inferences. Perhaps the most key concern with dealing with data missing due to attrition is assessing the degree of bias in retained variables attributable to attrition. Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses. Several different approaches can be considered and employed depending upon the nature of the intended analyses and degree of missingness and variables available to help estimate variables."
  },
  {
    "objectID": "manuscript_working_draft.html#quantifying-effect-sizes-longitudinally",
    "href": "manuscript_working_draft.html#quantifying-effect-sizes-longitudinally",
    "title": "1  Biostats WG Manuscript",
    "section": "3.8 Quantifying effect sizes longitudinally",
    "text": "3.8 Quantifying effect sizes longitudinally\nGiven longitudinal data involve different sources of variance, quantifying effect sizes longitudinally is a more difficult task compared to deriving such estimates from cross-sectional data. Effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (kraemer2014?). Common effect size metrics include r (i.e., the standardized covariance, or correlation, between two variables) and Cohen’s d (cohen1988?). Adjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., see morris2002?). (wang2019a?) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see wang2019a?, for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective data. (feingold2009?) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the resulting effect sizes were not in the same metric as effect sizes from traditional analysis (see feingold2009?, for more details). Given this issue, there have been various proposals to adjusting effect size measures in repeated assessments. (feingold2019?) reviews approaches for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (i.e., quadratic) growth factors. (morris2002?) review various equations for effect size calculations relevant to when combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance (as reviewed above). For example, within a RI-CLPM framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relations."
  },
  {
    "objectID": "autoregressive_cross-lagged_panel_models_main.html#appendix-chapter-5-examples-autoregressive-and-crosslaged-models",
    "href": "autoregressive_cross-lagged_panel_models_main.html#appendix-chapter-5-examples-autoregressive-and-crosslaged-models",
    "title": "ARCL Models",
    "section": "APPENDIX CHAPTER 5 EXAMPLES: AUTOREGRESSIVE AND CROSSLAGED MODELS",
    "text": "APPENDIX CHAPTER 5 EXAMPLES: AUTOREGRESSIVE AND CROSSLAGED MODELS\nUsing the xxxxx package, we evaluated the performance of the ARCL applied to longitudinal ABCD Study dataset to provide a practical example (all code available at [githublink]). For this example, we will consider the temporal association between youth report scores on the xxx (a measure of xxxxxxx) and yyy (a measure of xxxxxxx). First, we constructed a basic CLPM to simultaneously estimate the lagged association between xxxxxx (xt1) and subsequent yyyyy (yt2), as well as the lagged association between yyyyy (yt1) and subsequent xxxxx (xt2) (see single-headed arrow in Figure x, section xx). Results from this model reveal xxxxxxx (see Table x). However, the basic CLPM does not tell us anything about xxxx and assumes xxxxx.\n\nCHAPTER 5 TOC\n\n5.1: Basic Crosslagged Panel Model\n5.2: Crosslagged Panel Model w/contemporaneous effects\n5.3: Autoregressive Crosslagged Model\n\n\n\nEXAMPLE 5.1: Basic Cross-lag Panel Model (CLPM) with Continuous Indicators\n\nThe basic CLPM model does xxxxxxx.\nEXAMPLE 5.1 CODE \n--- \nTITLE: this is an example of a basic cross-lag panel model (only cross-lag parameters are modeled) with continuous indicators\nDATA: FILE IS example-data.dat; \nVARIABLE: NAMES ARE x1-x2 y1-y2; \nMODEL: y2 on x1;\n       x2 on y1;\n\n\n\nEXAMPLE 5.1 Diagram. This is an example of a basic cross-lag panel model (only cross-lag parameters are modeled) with continuous indicators.\n\n\n\n\nEXAMPLE 5.1 CODE COMMENTARY\nTITLE: this is an example of a CFA with continuous factor indicators\n\nThe TITLE command is used to provide a title for the analysis. The title is printed in the output just before the Summary of Analysis. \n\nDATA: FILE IS example-data.dat;\n\nThe DATA command is used to provide information about the data set to be analyzed. The FILE option is used to specify the name of the file that contains the data to be analyzed, ex5.1.dat. Because the data set is in free format, the default, a FORMAT statement is not required. \n\nVARIABLE: NAMES ARE x1-x2 y1-y2; \n\n*The VARIABLE command is used to provide information about the variables in the data set to be analyzed. The NAMES option is used to assign names to the variables in the data set. The data set in this example contains four variables: x1, x2, y1, y2.\n\n\nMODEL: y2 on x1;\n       x2 on y1;\n       \n\nThe MODEL command is used to describe the model to be estimated. Here the two BY statements specify that f1 is measured by y1, y2, and y3, and f2 is measured by y4, y5, and y6. The metric of the factors is set automatically by the program by fixing the first factor loading in each BY statement to 1. This option can be overridden. The intercepts and residual variances of the factor indicators are estimated and the residuals are not correlated as the default. The variances of the factors are estimated as the default. The factors are correlated as the default because they are independent (exogenous) variables. The default estimator for this type of analysis is maximum likelihood. The ESTIMATOR option of the ANALYSIS command can be used to select a different estimator.\n\n\n\n\n\nEXAMPLE 5.2: Cross-lag Panel Model (CLPM), including contemporaneous effects, with Continuous Indicators\n\nThe CLPM model with included contemporaneous effects does xxxxxxx.\nEXAMPLE 5.2 CODE \n--- \nTITLE: this is an example of a cross-lag panel model including contemporaneous effects, with Continuous Indicators\nDATA: FILE IS example-data.dat; \nVARIABLE: NAMES ARE x1-x2 y1-y2; \nMODEL: y2 on x1;\n       x2 on y1;\n       x1 with y1;\n       x2 with y2;\n\n\n\nEXAMPLE 5.2 Diagram. this is an example of a cross-lag panel model including contemporaneous effects, with Continuous Indicators.\n\n\n\n\nEXAMPLE 5.2 CODE COMMENTARY\nTITLE: this is an example of a cross-lag panel model including contemporaneous effects, with Continuous Indicators\n\nThe TITLE command is used to provide a title for the analysis. The title is printed in the output just before the Summary of Analysis. \n\nDATA: FILE IS example-data.dat;\n\nThe DATA command is used to provide information about the data set to be analyzed. The FILE option is used to specify the name of the file that contains the data to be analyzed, ex5.1.dat. Because the data set is in free format, the default, a FORMAT statement is not required. \n\nVARIABLE: NAMES ARE x1-x2 y1-y2;\n\nThe VARIABLE command is used to provide information about the variables in the data set to be analyzed. The NAMES option is used to assign names to the variables in the data set. The data set in this example contains six variables: y1, y2, y3, y4, y5, y6. Note that the hyphen can be used as a convenience feature in order to generate a list of names. \n\nMODEL: y2 on x1;\n       x2 on y1;\n       x1 with y1;\n       x2 with y2;\n\nThe MODEL command is used to describe the model to be estimated. Here the two BY statements specify that f1 is measured by y1, y2, and y3, and f2 is measured by y4, y5, and y6. The metric of the factors is set automatically by the program by fixing the first factor loading in each BY statement to 1. This option can be overridden. The intercepts and residual variances of the factor indicators are estimated and the residuals are not correlated as the default. The variances of the factors are estimated as the default. The factors are correlated as the default because they are independent (exogenous) variables. The default estimator for this type of analysis is maximum likelihood. The ESTIMATOR option of the ANALYSIS command can be used to select a different estimator.\n\n\n\n\nAutoregressive and cross-lagged panel analysis (ARCL)\nRank-order stability can be used to model interindividual stability over time as an autoregressive process,. That is, the rank-order stability can be used to model continuity of a behavior. Assuming equal intervals, the correlations between T0 and T1, and between T1 and T2 could be used to estimate the correlation between T2 and T3.\nMultilevel modeling approaches have often stressed methods to tease apart different sources of variance [e.g., distinguishing level-1, or within-person, variables from level-2, or between-person, variables in the context of prospective data; see (raudenbush2002?)]. However, models common in SEM, such as the CLPM, have been criticized extensively on the grounds this modeling approach cannot delineate between- and within-person sources of variation and covariations (see littlefield2021?, for a review). Briefly, the CLPM assumes no stable between-person differences (beyond the implied relations among the auto-regressive paths) among the constructs that are assessed repeated ly. As noted by (hamaker2015?), “…if stability of the constructs is to some extent of a trait-like, time-invariant nature, the inclusion of autoregressive parameters will fail to adequately control for this. As a result, the estimates of the cross-lagged regression coefficients will be biased, which may lead to erroneous conclusions regarding the underlying causal pattern.” (p. 10 2). As demonstrated by (littlefield2021?), the CLPM assumes relations identical to a series of two-predictor regression models in terms of estimating variances and covariances among measurements across ti me. As described above, regression models based on two waves of assessment are limited on several fronts, including being able to tease apart between- and within-person sources of variance. (hoffman2015?) notes the cross-lagged estimate “smushes” the between- and within-person effects together as a single estima te. (berry2017a?) notes this results in CLPM estimates “…that are difficult (or impossible) to interpret meaningfully.” (p. 118 7). Given these observations, and that prospective data are often used to inform theories involving clear within-person processes (e.g., see curran2011?), models that more optimally delineate between- and within-person sources of variance are need ed."
  },
  {
    "objectID": "autoregressive_cross-lagged_panel_models_main.html#what-it-is-and-when-to-use-it",
    "href": "autoregressive_cross-lagged_panel_models_main.html#what-it-is-and-when-to-use-it",
    "title": "ARCL Models",
    "section": "What it is and when to use it",
    "text": "What it is and when to use it\nThe cross lagged panel model (CLPM) is a flexible analytic approach that is commonly applied when researchers are interested in understanding how variables influence each other over time. This framework requires at least two variables assessed across two measurement occassions. Consider the most basic – and eponymously named– CLPM, which models the lagged associations between two variables (x, y). Let ‘x1’ and ‘y1’ denote variables x and y at time 1 and allow ‘x2’ and ‘y2’ denote variables x and y at time 2. This model compares the relative effects of x and y on each other (‘x1->y2’, ‘y1->x2’) (see Figure x) and can be easily extended to evaluate other hypothesized relationships. For example, evaluating contemporaneous associations between variables assessed during the same measurement occassion (e.g., ‘x1 <-> y1’; ‘x2 <-> y2’; see Figure x) is straightforward. Another common CLPM extension is the inclusion of autoregressive effects (e.g., ‘x1->x2’, ‘y1->y2’; see Figure x). Also referred to as an autoregressive cross-lagged [ARCL] model, this extension provides an estimate of a variable’s temporal (i.e., rank order) stability over time. The larger the value of the autoregressive coefficient (closer to 1) the more stable (greater % of variance explained in) the variable across measurement occasions. When contemporaneous (e.g., x1 <-> y1) and autoregressive effects (e.g., x1 -> x2) are included, the standardized cross-lagged parameters of an ARCL model are often inferred as representing the bidirectional ‘between-person’ effects of ‘x1->y2’ (when controlling for y1) and ‘y1->x2’ (when controlling for x1).\nOne advantage of longitudinal analyses with multiple waves of data collection is that such processes can be modeled over time. Understanding transactional effects effects can be useful in devising strategies to intervene in various types of escalating cycles of violence such as child maltreatment [(cicchetti2006a?)) or the effects of intimate partner violence on child behavior problems (chung2021?). Such processes could be modeled statistically in a number of ways by relying on estimating cross-lagged relations but require at least three times of measurement in order to distinguish beween-subject and within-sources of measurement [(hamaker2015?); see discussion below)."
  },
  {
    "objectID": "latent_growth_curves_main.html",
    "href": "latent_growth_curves_main.html",
    "title": "Latent Growth Curves",
    "section": "",
    "text": "Latent growth curve modeling (LGCM)\nLGM is a flexible modeling strategy that encompasses a set of statistical methods that allow for specifying and evaluating relationships among variables that have been assessed repeatedly across multiple measurement occasions (Preacher, et al. 2008). In its most basic form, LGM parameterizes a series of observations using two parameters, an intercept (often but not always the first observations of the series) and a slope. Each parameter has its own variance so that individual differences in level (at the point of the intercept) and rate of change (i.e., the slope) are captured. The LGM framework offers several noteworthy benefits compared to some other approaches common to longitudinal data analysis. For example, research focused on characterizing stability often resolves rank-order stability but doesn’t consider mean level change. This more traditional analytic approach investigates between-individual or “rank-order” change by focusing on an individual’s relative placement in a group across time (Hawes et al, 2018). While evaluating of rank-order stability can certainly offer useful insight, this approach provides little information regarding within-individual change (i.e., individual differences in slope). Additionally, LGM models are extremely flexible and can model both linear and a wide range of nonlinear slopes including slopes that follow polynomial trends, a discrete change in linear slope that occurs at a given point in time (e.g., spline), or can be relatively “free” and be fitted to model the observed variables as they appear. Note that, solely focusing on rank-order estimates can lead to fundamental misinterpretations such as concluding that a construct of interest is undergoing no substantial or meaningful change. For example, consider child A who takes part in a study and reports decreasing scores on a measure of anxiety across 4 measurement occasions. Now consider a hypothetical wherein all other youth taking part in the study exhibit similar decreases to their anxiety scores. In this instance, child A’s “rank-order” in the group may not change. This would result in relatively high stability estimates despite notable within-individual change to child A’s anxiety scores over time. The LGM framework effectively deals with this issue by allowing for an examination of both, intraindividual (within-person) change over time as well as interindividual (between-person) variability in these patterns of change. For many research questions, it is important to be able to resolve both normative change and variation in how individuals partake in that change. The implementation of an LGM framework can provide novel insight into continuity and change underlying phenomena of interest. A fundamental aspect of this approach is the ability to characterize the direction and rate of change at both, the group- and individual-level within a single model. In a conventional LGM a single trajectory that represents the overall group-mean is estimated, as well the individual variability around this mean trajectory. Further, extensions to the conventional LGM enable researchers to test more elaborate models. For example, theoretical accounts often hypothesize that different unobserved subpopulations of individuals in a population exhibit unique patterns of growth across development. More advanced LGM methods, including latent class growth analysis (LCGA) and growth mixture modeling (GMM), accommodate this increased complexity by estimating distinct trajectories that can differ in their direction and rate of change Kenny’s comment: Add citation. In addition to modeling growth, LGM methods allow researchers to evaluate other substantive questions relevant to continuity and change, such as the influence of time-varying covariates, antecedent predictors and consequences of change, and unidirectional and transactional processes among multiple growth processes. To better demonstrate applications and advantages of the LGM framework we now turn to several worked examples using real-world data from the ABCD Study Curated Annual Release 2.0 (MPlus and R code for all examples is provided in supplemental documents). Example data come from the youth self-report version of the Brief Problem Monitor (BPM; citation). The BPM is a rating instrument used to monitor children’s functioning and response to interventions. The measure includes 18-items scored on a 0 (“not true”) to 2 (“very true”) scale and is comprised of 3 subscales (Externalizing, Internalizing, Attention). BPM data used in the following examples was collected across 3 measurement occasions (i.e., 6-month, 1-year, and 18-month follow-up assessments) and only youth with complete BPM data at each assessment Kenny’s comment: I might say, for purposes of illustrations as we don’t want to encourage folks to routinely use listwise deletion were included in the worked examples (n = 1,864). All models were estimated using maximum likelihood estimation with robust standard errors (MLR). Model fit was assessed using several common fit indices (e.g., Comparative Fit Index [CFI; Hu & Bentler, 1999], Root Mean Square Error of Approximation [RMSEA; Browne, Cudeck, Bollen, & Long, 1993], sample-size adjusted Bayesian Information Criterion [BIC]. Example 1. The Conventional Latent Growth Model (LGM) A conventional LGM consists of repeated measurements of some variable ‘y’. In this model two latent factors are specified to represent facets of change in y over time. The first latent factor, the intercept, represents y at baseline or when the time variable is equal to 0 (t = 0). The second latent factor, the slope, represents linear change in y across the repeated measurements. In a conventional LGM the following six parameters are estimated: 1) intercept mean (μi); 2) intercept variance (θi); 3) slope mean (μs); 4) slope variance (θs); 5) intercept and slope covariance (θis); and 6) an error variance that remains constant across repeated measurements (θε). We will now evaluate a conventional LGM that was estimated using BPM Externalizing scale scores obtained across 3 measurement occasions. An examination of the Comparative Fit Index (CFI) and root mean square error of approximation (RMSEA) reveals evidence of poor model fit (CFI = .91; RMSEA = .25). Although CFI was within the generally acceptable range (i.e., >.90; citation), RMSEA was well above the generally recommended minimum cutoff (i.e., <.10; citation). This suggests it is necessary to reevaluate our specified model. In the context of the current example however, we shall proceed as though the model demonstrated adequate fit. Observing the model parameter estimates shows the mean estimated intercept (μ = 1.86, SE = 0.04) and linear slope (μ = -.09, SE = 0.02) to be significant (ps < .001). While the intercept factor provides information about initial status, some researchers suggest that this parameter is primarily meaningful for growth processes with a natural origin (Stoel, 2003; Stoel & van den Wittenboer, 2003). For the conventional LGM, the parameter that is most often of central interest is the slope factor. In the present example, the negative linear slope value indicates that there is a systematic mean-level decrease in BPM Externalizing scores across assessment waves (see Figure 1a). Importantly however, the variance estimate around this group-mean trajectory is statistically significant (θs = .38, p < .001). This indicates that although BPM Externalizing scores are decreasing on average, there is significant within-individual variability in these patterns of change (see Figure 1b)."
  },
  {
    "objectID": "growth_mixture_modeling_main.html",
    "href": "growth_mixture_modeling_main.html",
    "title": "Growth Mixture Modeling",
    "section": "",
    "text": "Growth mixture models (GMM)\nExample 2. Growth Mixture Modeling (GMM) On some occasions the conventional LGM may be limited in that it describes all individuals as coming from the same population, not accounting for potentially important subgroup effects. An important extension of the conventional model, GMM allows different unobserved subgroups to follow distinct trajectories. By allowing the intercept and slope growth factors to vary across groups, the GMM approach estimates a distinct group-mean trajectory with its own unique variance, for each latent class. A special case of GMM, LCGA models a separate trajectory for each latent class, but the growth factor variances [Clearer to say intercept and slope variances rather than growth factor?] within each class are fixed to zero (i.e., assumes homogenous within-class patterns of growth). As this approach is less computationally expensive, it is often a useful starting approach for identifying different underlying trajectories prior conducting a GMM. Expanding on our prior example, we now examine a GMM using the same BPM Externalizing scale scores used in the conventional model. A successive number of latent classes were specified across models and the optimal number of classes were determined by investigating recommended model selection criteria (e.g., adjusted Bayesian Information Criterion [aBIC], Bootstrapped Likelihood Ratio Test [BLRT], parsimony, and interpretability). An overview of criteria used to select the optimal number of trajectory classes is provided in Table 3. These results show aBIC to decrease across iterations, however, BLRT suggests a 4-class solution offers the optimal fit. Further, examination of the 5-class model reveals two classes that comprise less than 5% of the sample (class 3 n = 11 [< 1%]; class 4 n = 63 [3%]). Therefore, based on substantive interpretation, parsimony, and fit, we opt to select the four-class model of BPM Externalizing scores as providing the best overall solution. Estimated model parameters are presented in Table 4. Kenny’s comment regarding previous sentence: This is one of those areas where some might argue there are too many investigator degrees of freedom. I also wonder whether there should be discussion of other issues like factor mixture models. nonlinear\nresults show a small (n = 64; 4%) group of youth with a persistently high BPM Externalizing trajectory and large group of youth (n = 1437; 77%) following a low and decreasing trajectory. The remaining two classes were characterized by youth with moderate initial scores that decreased across assessments (n = 191; 10%) and youth with moderate scores that remained stable over time (n = 171; 9%) (see Figure 2). Kenny’s comment: I don’t see “figure 2” here. Also, I might label groups as “Moderate-High decreasing and Moderate -Low Stable. I say there because the intercept mean between the two”moderates” is larget than between Moderate Decreasing and Persistent High and between Moderate Stable and Low decreasing."
  },
  {
    "objectID": "random_intercept_cross-lagged_panel_models_main.html#what-it-is-and-when-to-use-it",
    "href": "random_intercept_cross-lagged_panel_models_main.html#what-it-is-and-when-to-use-it",
    "title": "RI-CLPM",
    "section": "What it is and when to use it",
    "text": "What it is and when to use it\nThe cross lagged panel model (CLPM) is a flexible analytic approach that is commonly applied when researchers are interested in understanding how variables influence each other over time. This framework requires at least two variables assessed across two measurement occassions. Consider the most basic – and eponymously named– CLPM, which models the lagged associations between two variables (x, y). Let ‘x1’ and ‘y1’ denote variables x and y at time 1 and allow ‘x2’ and ‘y2’ denote variables x and y at time 2. This model compares the relative effects of x and y on each other (‘x1->y2’, ‘y1->x2’) (see Figure x) and can be easily extended to evaluate other hypothesized relationships. For example, evaluating contemporaneous associations between variables assessed during the same measurement occassion (e.g., ‘x1 <-> y1’; ‘x2 <-> y2’; see Figure x) is straightforward. Another common CLPM extension is the inclusion of autoregressive effects (e.g., ‘x1->x2’, ‘y1->y2’; see Figure x). Also referred to as an autoregressive cross-lagged [ARCL] model, this extension provides an estimate of a variable’s temporal (i.e., rank order) stability over time. The larger the value of the autoregressive coefficient (closer to 1) the more stable (greater % of variance explained in) the variable across measurement occasions. When contemporaneous (e.g., x1 <-> y1) and autoregressive effects (e.g., x1 -> x2) are included, the standardized cross-lagged parameters of an ARCL model are often inferred as representing the bidirectional ‘between-person’ effects of ‘x1->y2’ (when controlling for y1) and ‘y1->x2’ (when controlling for x1).\nOne advantage of longitudinal analyses with multiple waves of data collection is that such processes can be modeled over time. Understanding transactional effects effects can be useful in devising strategies to intervene in various types of escalating cycles of violence such as child maltreatment [(cicchetti2006a?)) or the effects of intimate partner violence on child behavior problems (chung2021?). Such processes could be modeled statistically in a number of ways by relying on estimating cross-lagged relations but require at least three times of measurement in order to distinguish beween-subject and within-sources of measurement [(hamaker2015?); see discussion below)."
  },
  {
    "objectID": "latent_curve_model_with_structured_residuals_main.html",
    "href": "latent_curve_model_with_structured_residuals_main.html",
    "title": "LCM-SR",
    "section": "",
    "text": "Latent Curve Models with Structural Residuals (LCM-SR)\nmultivariate Latent Curve Model with Structured Residuals (LCM-SR; Curran et al., 2014) (see Figure 1). The LCM-SR model is a novel methodology that extends current analytic procedures by allowing more precise investigation into estimates of person- specific, “between-person” and time-specific, “within-person” processes among distinct constructs over time (Curran et al., 2014). This model has the ability to simultaneously estimate the association between psychopathic features and alcohol use across development, while also isolating the between-person and within-person components of these processes over time (see Curran et al., 2014). The multivariate LCM-SR has similarities to other models that have also extended the more general latent curve model (LCM) framework, such as autoregressive latent trajectory (ALT; Curran & Bollen, 2001; Bollen & Curran, 2004) models. However, unlike previous methods, a major advantage of the LCM-SR framework is that it imposes a structure onto the time- specific residuals of the observed repeated measures for each process (e.g., psychopathic features and alcohol use). This structure results in these residuals being conceptualized as time-specific estimates of the deviation between the observed repeated measure and the underlying latent growth curve. This time-specific residual structure represents the within- person portion of the model (Curran et al., 2014). It is possible to incorporate both autoregressive and cross-lagged regressions in this within-person portion of the model,\nLCM-SR models require a model building process that is carried out in a series of steps (Curran et al., 2014). More simple models are specified initially such as evaluating the fit of separate univariate growth models for each process (i.e., psychopathic features, alcohol use). Subsequent models increase in complexity and the ability of this added complexity to improve the model is evaluated at each step by examining the results Satorra-Bentler chi- square difference testing (Satorra & Bentler, 2001), as well as evaluation of additional fit indices (e.g., CFI, RMSEA, BIC, Wald tests).\nIn the current study, after finding each of our univariate growth curve models to provide a good fit to the data, our first step was to combine the trajectories of psychopathic features and alcohol use into a parallel process Latent Growth Curve Model (LGCM). Next we imposed a structure onto the time-specific residuals and specified a model consisting of autoregressive and cross-lagged parameters of this residual structure. In the subsequent step the full LCM-SR model was specified by combining the parallel process LGCM with the autoregressive and cross-lagged residual structure. Finally, we compared the fit of a series of models resulting from fixing and freeing parameters of the trajectory portion of the model (i.e., slope variance for alcohol use and psychopathic features) and the residual structure aspect of the model (i.e., concurrent time-specific correlations, autoregressions, and crosslags). All models were specified using maximum likelihood estimation with standard errors and a chi-square statistic that are robust to nonnormality (MLR) in Mplus 7 (Muthén & Muthén, 1998–2012) (also see Bollen & Curran, 2004, 2006; Curran et al., 2014; Morin, Maiano, Marsh, Janosz, and Nagengast, 2011)."
  }
]